{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a62be09-6e30-4bfa-8a7e-05938cbb18d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/code/jupyter/.venv/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.0-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc204eb-eb3c-4f15-9e1f-e0b2f81b2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_bnl_value ( pts, bnl ) :\n",
    "\n",
    "    ## fixed the hardway\n",
    "    \n",
    "    updates = [\n",
    "        {\"effective_date\":\"2018-12-10\",\"cost\":22043.0},\n",
    "        {\"effective_date\":\"2018-12-17\",\"cost\":44951.0},\n",
    "        {\"effective_date\":\"2019-01-04\",\"cost\":33150},\n",
    "        {\"effective_date\":\"2019-01-15\",\"cost\":27007},\n",
    "        {\"effective_date\":\"2019-01-23\",\"cost\":27665},\n",
    "        {\"effective_date\":\"2019-03-15\",\"cost\":27977.25},\n",
    "        {\"effective_date\":\"2019-03-22\",\"cost\":31480},\n",
    "        {\"effective_date\":\"2019-03-26\",\"cost\":30732.80},\n",
    "        {\"effective_date\":\"2019-04-04\",\"cost\":22238},\n",
    "        {\"effective_date\":\"2019-10-07\",\"cost\":41898}\n",
    "    ]\n",
    "    \n",
    "    for idx in range ( len ( updates ) ) :\n",
    "\n",
    "        pts_mask = (pts.effective_date==updates[idx]['effective_date']) & (pts['cost']==updates[idx]['cost'])\n",
    "        bnl_mask = (bnl.effective_date==updates[idx]['effective_date']) & (bnl.total_installed_price==-1)\n",
    "\n",
    "        bnl.loc[bnl_mask,'total_installed_price'] = pts.loc[pts_mask,'cost'].values\n",
    "        \n",
    "        return bnl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ec6dbbf-f278-4660-bb96-6223da362413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sources_from_extracts(data_dir = '/data/energy/REC/MA/Arlington/'):\n",
    "\n",
    "    rps             =  pd  . read_csv  ( data_dir + 'rps.tsv' , sep = '\\t'  )\n",
    "    pts             =  pd  . read_csv  ( data_dir + 'pts.tsv' , sep = '\\t'  )\n",
    "    bnl             =  pd  . read_csv  ( data_dir + 'bnl.tsv' , sep = '\\t'  )\n",
    "    solar_systems   =  gpd . read_file ( data_dir + 'solar_systems.geojson' )   ##truth, tokenId is key\n",
    "\n",
    "    # solar_systems.tokenId.apply(type).unique()  change from int to string to perserve precision\n",
    "    solar_systems.tokenId = solar_systems.tokenId.astype(str)\n",
    "    solar_systems.permit_effective_date = pd.to_datetime(solar_systems.permit_effective_date)\n",
    "\n",
    "\n",
    "    rps . effective_date  =  pd . to_datetime ( rps . effective_date )\n",
    "    pts . effective_date  =  pd . to_datetime ( pts . effective_date )\n",
    "    bnl . effective_date  =  pd . to_datetime ( bnl . effective_date )\n",
    "\n",
    "    for col in bnl.columns:\n",
    "        mask = (bnl[col] == '-1') | (bnl[col] == '-1.0')\n",
    "        bnl.loc[mask,col] = ''\n",
    "        mask = (bnl[col] == -1) | (bnl[col] == -1.0)\n",
    "        bnl.loc[mask,col] = np.nan\n",
    "    \n",
    "    \n",
    "    return rps, pts, bnl, solar_systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a66c0d-3a3b-4536-856d-a6adff843ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rps_pts_comparison_tests(rps_pts):\n",
    "\n",
    "    ## 925 out of 1082, most are rps installs not yet in pts, see above\n",
    "    mask = rps_pts.source == 'both'\n",
    "\n",
    "    # 259 differences out of 925 merged rps/pts\n",
    "    # 139 more than 10 days apart\n",
    "    test = rps_pts.effective_date_rps!= rps_pts.effective_date_pts\n",
    "\n",
    "    test = (rps_pts.effective_date_rps - rps_pts.effective_date_pts).apply(np.abs) > timedelta(days=60)\n",
    "    cols = ['rps_index','pts_index','effective_date_rps','effective_date_pts']\n",
    "    print('\\nDifferences in Effective Date (>60 days)\\n')\n",
    "    print(rps_pts[mask & test][cols].to_markdown())\n",
    "\n",
    "    test = rps_pts.kW_rps!= rps_pts.kW_pts\n",
    "    test = (rps_pts.kW_rps- rps_pts.kW_pts).apply(np.abs)>=0.0051\n",
    "\n",
    "    cols = ['rps_index','pts_index','kW_rps','kW_pts']\n",
    "    print('\\nDifferences in Capacity (>0.0051kW)\\n')\n",
    "    print(rps_pts[mask & test][cols].to_markdown())\n",
    "\n",
    "\n",
    "    cols = ['rps_index','pts_index','cost_rps','cost_pts']\n",
    "\n",
    "    test = rps_pts.cost_rps!= rps_pts.cost_pts\n",
    "    # 11 >$10, 9>$100, 7>$1000\n",
    "    test = (rps_pts.cost_rps- rps_pts.cost_pts).apply(np.abs)>1000\n",
    "    print('\\nDifferences in Cost (>$1000)\\n')\n",
    "    print(rps_pts[mask & test][cols].to_markdown())\n",
    "\n",
    "\n",
    "def merge_rps_pts(rps, pts, data_dir = '/data/energy/REC/MA/Arlington/'):\n",
    "    \n",
    "    rps_pts_xref = pd . read_csv ( data_dir + 'rps_pts_xref.tsv' , sep = '\\t' )\n",
    "    print('RPS dups:',rps_pts_xref.rps.duplicated().any(),'\\nPTS dups:',rps_pts_xref.pts.duplicated().any())\n",
    "\n",
    "\n",
    "    rps = rps.merge(rps_pts_xref,right_on='rps',left_index=True,how='left').reset_index(drop=True)\n",
    "    pts = pts.merge(rps_pts_xref,right_on='pts',left_index=True,how='left').reset_index(drop=True)\n",
    "\n",
    "    ##???\n",
    "    rps_pts = rps.merge(pts,left_on='pts',right_index=True,how='outer',indicator=True).reset_index(drop=True)\n",
    "\n",
    "    rps_pts.columns=rps_pts.columns \\\n",
    "                    .str.replace('_x$','_rps',regex=True) \\\n",
    "                    .str.replace('_y$','_pts',regex=True) \\\n",
    "                    .str.replace('^rps_rps$','rps_index',regex=True) \\\n",
    "                    .str.replace('^pts$','pts_index',regex=True)\n",
    "\n",
    "    rps_pts['source'] = rps_pts._merge.astype(str)\n",
    "    #rps_pts.columns = rps_pts.columns.str.replace('_merge','source')\n",
    "\n",
    "    mask = rps_pts.source=='left_only'\n",
    "    rps_pts.loc[mask,'source'] = 'rps'\n",
    "\n",
    "    mask = rps_pts.source=='right_only'\n",
    "    rps_pts.loc[mask,'source'] = 'pts'\n",
    "\n",
    "    rps_pts.drop(['rps_pts','pts_pts','pts_rps','_merge'],axis=1,inplace=True)\n",
    "    \n",
    "    mask = rps_pts.source == 'both'\n",
    "\n",
    "    for scalar in ['installer', 'owner', 'type', 'city', 'zip', 'utility']:\n",
    "\n",
    "        rps_pts[scalar]=rps_pts[scalar+'_rps']  #default to rps\n",
    "\n",
    "        test = rps_pts[scalar+'_rps']!= rps_pts[scalar+'_pts']\n",
    "        print(scalar,'#diffs=',len(rps_pts[mask&test]))\n",
    "        more = pd.isnull(rps_pts[scalar])\n",
    "        rps_pts.loc[more, scalar] = rps_pts.loc[more,scalar+'_pts']\n",
    "        rps_pts.drop([scalar+'_rps',scalar+'_pts'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ## fix zipcode, missing leading '0' for Arlington and others but not all\n",
    "    mask = rps_pts.zip.astype(str).apply(len) ==4\n",
    "    rps_pts.loc[mask,'zip'] = '0' + rps_pts['zip'].astype(str)\n",
    "\n",
    "\n",
    "    rps_pts.name=rps_pts.name.astype(str)\n",
    "    \n",
    "    run_rps_pts_comparison_tests(rps_pts)    \n",
    "\n",
    "    empty_columns = ['location','location_tranche', 'off_taker', 'off_taker_tranche', 'tracking','tracking_tranche', 'pollinator', 'pollinator_tranche']\n",
    "    cols = rps_pts.columns\n",
    "    for col in cols:\n",
    "        mask = ~pd.isnull(rps_pts[col])\n",
    "        if len(rps_pts[mask])==0:\n",
    "            print('dropping',col)\n",
    "            rps_pts.drop(col,axis=1,inplace=True)\n",
    "\n",
    "    droppers = ['project','perWatt_rps','perWatt_pts','install_yr','distributer']\n",
    "    for col in droppers:\n",
    "        rps_pts.drop(col,axis=1,inplace=True)\n",
    "    rps_pts.columns\n",
    "\n",
    "    rps_pts['kW'] = rps_pts['kW_rps']\n",
    "    mask = pd.isnull(rps_pts['kW'])\n",
    "    rps_pts.loc[mask,'kW'] = rps_pts.loc[mask,'kW_pts']\n",
    "\n",
    "    rps_pts['cost'] = rps_pts['cost_rps']\n",
    "    mask = pd.isnull(rps_pts['cost'])\n",
    "    rps_pts.loc[mask,'cost'] = rps_pts.loc[mask,'cost_pts']\n",
    "\n",
    "    rps_pts.drop(['kW_rps','kW_pts','cost_rps','cost_pts'],axis=1,inplace=True)\n",
    "\n",
    "    rps_pts[rps_pts.duplicated('pts_index',keep=False)]\n",
    "    print('null rps_ids',len(rps_pts[pd.isnull(rps_pts.rps_id)]))\n",
    "\n",
    "    \n",
    "    return rps_pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c53b325-4ba3-4798-aaee-a4f82004d7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tokenId', 'image', 'name', 'description', 'attributes', 'entity',\n",
       "       'financials', 'dates', 'location', 'amps', 'watts', 'joules', 'ohm',\n",
       "       'xref', 'governance', 'geometry2', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/data/energy/REC/MA/Arlington/'\n",
    "solar_systems   =  gpd . read_file ( data_dir + 'solar_systems.geojson' )\n",
    "solar_systems.columns#iloc[0]['tokenId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e55d572-2fef-4091-bfbe-1575c3c0a480",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeoDataFrame' object has no attribute 'permit_effective_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18822/3098490591.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolar_systems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sources_from_extracts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_missing_bnl_value\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbnl\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbnl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bnl_index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrps_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_rps_pts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data/energy/REC/MA/Arlington/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18822/3334690995.py\u001b[0m in \u001b[0;36mget_sources_from_extracts\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# solar_systems.tokenId.apply(type).unique()  change from int to string to perserve precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msolar_systems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolar_systems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msolar_systems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermit_effective_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolar_systems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermit_effective_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/code/jupyter/.venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5476\u001b[0m         ):\n\u001b[1;32m   5477\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeoDataFrame' object has no attribute 'permit_effective_date'"
     ]
    }
   ],
   "source": [
    "rps, pts, bnl, solar_systems = get_sources_from_extracts()\n",
    "bnl = fix_missing_bnl_value ( pts, bnl )\n",
    "bnl['bnl_index'] = bnl.index\n",
    "rps_pts = merge_rps_pts(rps, pts, data_dir = '/data/energy/REC/MA/Arlington/')\n",
    "\n",
    "print ( \"RPS: {rps}\\nPTS: {pts}\\nBNL: {bnl}\\nPermits: {ss}\".format(rps=len(rps),pts=len(pts),bnl=len(bnl),ss=len(solar_systems)) )\n",
    "print ( \"\\nAs of 12/31/2020\\n\")\n",
    "print ( \"RPS: {rps}\\nPTS: {pts}\\nBNL: {bnl}\\nPermits: {ss}\".format(rps=len(rps[rps.effective_date<='2020-12-31']),\n",
    "                                                                   pts=len(pts[pts.effective_date<='2020-12-31']),\n",
    "                                                                   bnl=len(bnl[bnl.effective_date<='2020-12-31']),\n",
    "                                                                   ss=len(solar_systems[solar_systems.permit_effective_date<='2020-12-31'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cccad4-239c-4a72-8a21-96bbd75a90a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e02e65-78a0-4c7e-b897-ffa45b108902",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first round, merge on SMART project, renamed rps_id and BNL system_ID_1; about 170 matches\n",
    "mask = (~pd.isnull(rps_pts.rps_id)) #&(rps_pts.source=='both')\n",
    "foo=rps_pts[mask].merge(bnl,how='left',left_on=['rps_id'],right_on='system_ID_1',indicator=True)\n",
    "\n",
    "combo = foo[foo._merge=='both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6c50c-82f8-4419-9368-3d03f391a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.duplicated('rps_index').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84329c6-0e1e-49e4-81de-e939d2e5b0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed4f97-c752-4532-927b-41903befa4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##second round\n",
    "rps_mismatch = foo[foo._merge=='left_only']\n",
    "rps_mismatch.columns=rps_mismatch.columns.str.replace('_x$','',regex=True)\n",
    "rps_mismatch = rps_mismatch[rps_pts.columns]\n",
    "\n",
    "foo=rps_mismatch.merge(bnl,how='left',left_on=['effective_date_pts','cost'],right_on=['effective_date','total_installed_price'],indicator=True)\n",
    "\n",
    "##dups on merge\n",
    "mask =  ((foo.pts_index==741) & (foo.bnl_index==426))  | \\\n",
    "        ((foo.pts_index==744) & (foo.bnl_index==423))  |  \\\n",
    "        ((foo.pts_index==738) & (foo.bnl_index==432))  |   \\\n",
    "        ((foo.pts_index==739) & (foo.bnl_index==430))  |    \\\n",
    "        ((foo.pts_index==436) & (foo.bnl_index==667))  |     \\\n",
    "        ((foo.pts_index==437) & (foo.bnl_index==666))  |      \\\n",
    "        ((foo.pts_index==322) & (foo.bnl_index==821))  |       \\\n",
    "        ((foo.pts_index==321) & (foo.bnl_index==784))  \n",
    "\n",
    "foo = foo[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa9c5d-4a14-4f3b-aefd-9fbe77aeae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = combo.append(foo[foo._merge=='both'])\n",
    "combo.drop('_merge',axis=1,inplace=True)\n",
    "\n",
    "rps_mismatch = foo[foo._merge=='left_only']\n",
    "rps_mismatch.columns=rps_mismatch.columns.str.replace('_x$','',regex=True)\n",
    "rps_mismatch = rps_mismatch[rps_pts.columns]\n",
    "rps_mismatch\n",
    "\n",
    "bnl_mismatch = foo[foo._merge=='right_only']\n",
    "bnl_mismatch.columns=bnl_mismatch.columns.str.replace('_y$','',regex=True)\n",
    "bnl_mismatch = bnl_mismatch[bnl.columns]\n",
    "bnl_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb4678-0d59-47fa-9e3a-c7fad94dd8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = ((rps_mismatch.status == 'Approved') | (pd.isnull(rps_mismatch.status))) &\\\n",
    "    ((rps_mismatch.effective_date_rps<='2020-12-31')|(rps_mismatch.effective_date_pts<='2020-12-31'))\n",
    "print('combo',len(combo),'combo mismatched',len(rps_mismatch[mask]))\n",
    "\n",
    "print(\"BNL:{bnl},COMBO:{combo}\".format(bnl=len(bnl),combo=len(combo)))\n",
    "\n",
    "##missing, 40>31 mist be some dups in combo??\n",
    "list(combo.columns)\n",
    "mask = bnl.bnl_index.isin(list(combo.bnl_index))\n",
    "print('bnl mismatched',len(bnl[~mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e588783-a3cc-4ebd-aa40-60e3b3ab68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = combo.city_x!=combo.city_y\n",
    "if len(combo[mask])==0:\n",
    "    combo['city'] = combo['city_x']\n",
    "    combo.drop(['city_x','city_y'],axis=1,inplace=True)\n",
    "else:\n",
    "    print('mistmatch on city',len(combo[mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc7c252-d2ab-4832-a78c-7953a6ce632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##15 instances of BNL and PTS disagree on zipcode, use PTS and fix zip code\n",
    "combo['zipcode'] = combo['zip_code'].astype(str)\n",
    "\n",
    "mask = combo['zipcode'].apply(len) ==4\n",
    "combo.loc[mask,'zipcode'] = ('0' + combo.loc[mask,'zipcode'].astype(str))\n",
    "\n",
    "mask = combo['zip']!=combo.zip_code\n",
    "print(combo[mask][['zip','zip_code','zipcode']].to_markdown())\n",
    "\n",
    "combo.drop(['zip','zip_code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e3281-5845-47b5-b4fe-ad2b3b6e21a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_keys = {\n",
    "    \"attributes\": [\n",
    "        'expansion_system',\n",
    "        'multiple_phase_system',\n",
    "        'new_construction',\n",
    "        'tracking',\n",
    "        'ground_mounted',\n",
    "        'third_party_owned',\n",
    "        'self_installed'\n",
    "    ],\n",
    "\n",
    "    \"entity\" : [\n",
    "        'applicant',\n",
    "        'ownership_type',\n",
    "        'status',\n",
    "        'capacity_block',\n",
    "        'installer',\n",
    "        'owner',\n",
    "        'type',\n",
    "        'sector',\n",
    "        'subsector',\n",
    "        'name',\n",
    "        'program',\n",
    "        'customer_segment',\n",
    "        'installer_name',\n",
    "        'aggregation',\n",
    "        'low_income',\n",
    "    ],\n",
    "    \n",
    "    \"financials\" : [\n",
    "        'ownership_type',\n",
    "        'applicant',\n",
    "        'program',\n",
    "        'contractor',\n",
    "        'installer',\n",
    "        'srec',\n",
    "        'srec_factor',\n",
    "        'cost',\n",
    "        'total_installed_price',\n",
    "        'rebate_or_grant',\n",
    "        'grant',\n",
    "        'permits',\n",
    "        'issued',\n",
    "        'descriptions',\n",
    "        'value',\n",
    "        'fee',\n",
    "    ],\n",
    "\n",
    "    \"dates\" : [\n",
    "        'effective_date',\n",
    "        'effective_date_rps',\n",
    "        'effective_date_pts',\n",
    "        'effective_date_permit',\n",
    "        'installation_date',\n",
    "        'expiration_date',\n",
    "        'operation_date',\n",
    "        'sq_date',\n",
    "        'qualification_date',\n",
    "        'dateOfBatteryInstall'\n",
    "    ],\n",
    "\n",
    "    \"location\" : [\n",
    "        'coord',\n",
    "        \"street_number\",\n",
    "        \"street_name\",\n",
    "        \"unit\" ,\n",
    "        'city',\n",
    "        'county',\n",
    "        'state',\n",
    "        'zipcode'\n",
    "    ],\n",
    "\n",
    "    \n",
    "    \"amps\": [\n",
    "        'distributor',\n",
    "        'utility',\n",
    "        'utility_service_territory',\n",
    "        'meter_mfgr',\n",
    "        'meter_type',\n",
    "        'interconnection'\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"watts\": [\n",
    "        \"kW\",\n",
    "        \"system_size_DC\",\n",
    "        \"est_annual_kWh\",\n",
    "        \"module_mfgr\",\n",
    "        \"inverter_mfgr\",\n",
    "        \"size\",\n",
    "        \"kW_ac\",\n",
    "        \"additional_modules\",\n",
    "        \"additional_inverters\",\n",
    "        'DC_optimizer',\n",
    "        'inverter_loading_ratio',\n",
    "    ],\n",
    "\n",
    "    \"joules\": [\n",
    "        'storage',\n",
    "        'storage_tranche',\n",
    "        'storage_kVa',\n",
    "        'storage_duration',\n",
    "        'battery_manufacturer',\n",
    "        'battery_model',\n",
    "        'battery_rated_capacity_kW',\n",
    "        'battery_rated_capacity_kWh'       \n",
    "    ],\n",
    "\n",
    "    \"ohm\" : [\n",
    "        \"parcel_size\" ,\n",
    "        \"style\",\n",
    "        \"year_built\",\n",
    "        \"stories\",\n",
    "        \"units\",\n",
    "        \"rooms\",\n",
    "        \"gross_area\",\n",
    "        \"living_area\",\n",
    "    ],\n",
    "    \n",
    "    \"xref\" : [\n",
    "        'pts_index',\n",
    "        'rps_index',\n",
    "        'bnl_index',\n",
    "    ],\n",
    "    \n",
    "    \"governance\" : [\n",
    "        \"parcel\",\n",
    "        \"land_use\",\n",
    "        \"land_use_code\",\n",
    "        \"zoning\",\n",
    "        \"location\",\n",
    "        \"map\",\n",
    "        \"plan\",\n",
    "        \"cama\",\n",
    "        \"deed_book\",\n",
    "        \"deed_page\",\n",
    "        \"rps_id\",\n",
    "        \"nepool_id\", \n",
    "        'data_provider_1',\n",
    "        'data_provider_2',\n",
    "        'system_ID_1',\n",
    "        'system_ID_2',\n",
    "    ] ,\n",
    "}\n",
    "#list(combo.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745a01e-4369-4a4e-9685-a8ffed99f32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827838cc-f2b2-4eec-8c1b-9d3c32928d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['pts_index','rps_index','bnl_index']:\n",
    "    combo[col] = combo[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c895c-7914-4e29-bbb8-28bad014badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rps[rps.name.str.contains('FranSullivan')==True][['cost']]\n",
    "##bnl_index has a dup at #416\n",
    "combo[combo.duplicated('pts_index',keep=False)]#[identity+dates+financials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83393c63-df27-4b65-9783-1dd7b8e71a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecf0c1-0d05-43ed-9119-e9b1b5abcec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##single instance; drop system_size_DC but just here?\n",
    "mask = combo.kW!=combo.system_size_DC\n",
    "print(combo[mask][['kW','system_size_DC']].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b8fc6-5887-4c07-9051-c78285fbf54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.reset_index(drop=True).to_csv(data_dir+'rps_pts_bnl.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640daae-9ec1-4d75-804a-8960351331f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc5e2e-4437-42a5-9c82-c494584e7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_job():\n",
    "\n",
    "    p1 = solar_systems.sort_values(['effective_date','permit_value','owner','tokenId']).reset_index()\n",
    "\n",
    "    p2 = combo.sort_values(['effective_date','cost']).reset_index()\n",
    "\n",
    "    if p1.duplicated('tokenId').any():\n",
    "        print('Dups in permits!!')\n",
    "\n",
    "    p1[['effective_date','permit_value','owner','tokenId']]\n",
    "    p1.to_csv('/data/energy/REC/MA/Arlington/p1.tsv',sep='\\t')\n",
    "    p2.to_csv('/data/energy/REC/MA/Arlington/p2.tsv',sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ab92c-8b14-4484-8d14-1d8509132085",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_permits_xref = pd.read_csv('/data/energy/REC/MA/Arlington/pts_permits_xref_20211217.tsv',sep='\\t')\n",
    "mask = (~pd.isnull(pts_permits_xref.pts_index)) #& (~pts_permits_xref.pts_index.str.contains('\\&'))\n",
    "pts_permits_xref[mask].pts_index.apply(type).unique()\n",
    "secondaries = pts_permits_xref[mask][pts_permits_xref[mask].pts_index.str.contains('&')]\n",
    "print(secondaries.to_markdown())\n",
    "\n",
    "pts_permits_xref = pts_permits_xref[mask][~pts_permits_xref[mask].pts_index.str.contains('&')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a49ab-c171-4d5b-8df4-e01ca6c76126",
   "metadata": {},
   "outputs": [],
   "source": [
    "scols = ['ADDR_NUM', 'FULL_STR', 'LOCATION', 'MAP_PAR_ID', 'LOC_ID', \n",
    "       'MAP_NO',  'PLAN_ID', 'CAMA_ID','OWNER1',\n",
    "       'permits', 'descriptions', 'contractor',\n",
    "       'owner', 'permit_value', 'permit_fee', 'issued', 'effective_date',\n",
    "        'tokenId', 'coord', 'image', 'geometry','shared',\n",
    "         'LOT_SIZE', 'LS_DATE', 'LS_PRICE', 'USE_CODE',\n",
    "        'LS_BOOK', 'LS_PAGE', 'ZONING', 'YEAR_BUILT', 'BLD_AREA',\n",
    "       'UNITS', 'RES_AREA', 'STYLE', 'STORIES', 'NUM_ROOMS',\n",
    "       ]\n",
    "ss = solar_systems[scols].copy()\n",
    "\n",
    "scols = ['street_number', 'street_name', 'unit', 'parcel', 'location', \n",
    "       'map', 'plan', 'cama','property_owner',\n",
    "       'permits', 'descriptions', 'contractor',\n",
    "       'permit_owner', 'value', 'fee', 'issued', 'effective_date_permit',\n",
    "        'tokenId', 'coord', 'image','geometry','shared_install',\n",
    "         'parcel_size', 'last_sale_date', 'last_sale_price', 'land_use_code',\n",
    "        'deed_book', 'deed_page', 'zoning', 'year_built', 'gross_area',\n",
    "       'units', 'living_area', 'style', 'stories', 'rooms',\n",
    "       ]\n",
    "\n",
    "ss.columns = scols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addd81f-627f-406c-9911-820e642a2d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f5828-aecc-4066-badc-0cdbc3c3406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_permits_xref.tokenId = pts_permits_xref.tokenId.astype(str)\n",
    "pts_permits_xref.pts_index = pts_permits_xref.pts_index.astype(int)\n",
    "#solar_systems.drop(\"_merge\",axis=1,inplace=True)\n",
    "#cols = identity+location+entity+attributes+dates+financials+watts+amps+joules\n",
    "\n",
    "\n",
    "super_combo = ss \\\n",
    "    .merge(pts_permits_xref,on='tokenId',how='left',indicator=True) \\\n",
    "    .merge(combo,on='pts_index',how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f066a-e2b5-4e10-a07f-c6c6a4bdbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = super_combo[super_combo._merge=='both'] . reset_index ( drop = True )\n",
    "# for col in data.columns:\n",
    "#     print(col)\n",
    "#     data.loc[data[col]==-1,col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7cf87-0f12-435b-b041-4f9e1105b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in metadata_keys['dates']:\n",
    "    print(col,data[col].apply(type).unique())\n",
    "    \n",
    "for col in ['effective_date','effective_date_rps','effective_date_pts','effective_date_permit']:\n",
    "    data[col] = pd.to_datetime(data[col]).dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "for col in metadata_keys['dates']:\n",
    "    print(col,data[col].apply(type).unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189cc754-877a-45f1-83fa-6116f5b45c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_dict( df, cols):\n",
    "    return {k: v for k, v in df[cols].to_dict().items() if (v is not np.nan) and (v != '') and (v==v)}\n",
    "\n",
    "\n",
    "PV          =  [ ] \n",
    "\n",
    "for jdx in range(len(data)):\n",
    "    \n",
    "    row = data.iloc[jdx]\n",
    "\n",
    "    metadata = {\n",
    "        \"tokenId\": row.tokenId,\n",
    "        \"image\" : row.image,\n",
    "        \"name\": row.street_number + ' ' + row.street_name,\n",
    "        \"description\": \"A {kW}kW photovoltaic system was installed at {address} on {effective_date} at a cost of {cost} by {installer} through the {program}\". \\\n",
    "            format(kW=row.kW,\n",
    "                   address=row.street_number + ' ' + row.street_name,\n",
    "                   effective_date=row.effective_date,\n",
    "                   cost=row.cost,\n",
    "                   installer=row.installer,\n",
    "                   program=row.program\n",
    "                  )\n",
    "    }\n",
    "        \n",
    "\n",
    "    for key in metadata_keys.keys():\n",
    "        metadata[key] = convert_to_dict(row,metadata_keys[key])\n",
    "\n",
    "\n",
    "    cols = {\n",
    "        \"modules\" : {\n",
    "            \"cols\" : [\"azimuth\" , \"tilt\" , \"manufacturer\" , \"model\", \"quantity\" , \"technology\" , \"BIPV\", \"bifacial\" , \n",
    "                      \"nameplate_capacity\" , \"efficiency\"],\n",
    "            \"dicts\": [\"azimuth\" , \"tilt\" , \"module_manufacturer\" , \"module_model\", \"module_quantity\" , \"technology_module\" , \"BIPV_module\", \n",
    "                      \"bifacial_module\" , \"nameplate_capacity_module\" , \"efficiency_module\" ]\n",
    "        },\n",
    "        \"inverters\" : {\n",
    "            \"cols\" : [\"manufacturer\",    \"model\" ,    \"quantity\" ,    \"micro\",    \"solar_storage_hybrid\",    \"built_in_meter\",    \"output_capacity\"],\n",
    "            \"dicts\": [\"inverter_manufacturer\",    \"inverter_model\" ,    \"inverter_quantity\" ,    \"micro_inverter\",    \"solar_storage_hybrid_inverter\",    \n",
    "                      \"built_in_meter_inverter\",    \"output_capacity_inverter\"]        \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    token_type='watts' \n",
    "\n",
    "    for sub_dicts in ['modules','inverters']:\n",
    "\n",
    "        metadata[token_type][sub_dicts] = [ ]\n",
    "\n",
    "        xref = dict(zip(cols[sub_dicts][\"cols\"] , cols[sub_dicts][\"dicts\"]))\n",
    "\n",
    "        for idx in range(3):\n",
    "            x_dict = dict ( )\n",
    "            for col in cols[sub_dicts][\"cols\"]:\n",
    "                x = row[xref[col]+'_'+str(idx+1)]#.value\n",
    "                if x != None:\n",
    "                    if x !='':\n",
    "                        if x !=np.nan:\n",
    "                            if x==x:\n",
    "                                x_dict[col] = x\n",
    "\n",
    "            if len(x_dict)>0:\n",
    "                metadata[token_type][sub_dicts].append(x_dict)\n",
    "                \n",
    "    metadata[\"geometry\"] = row.geometry  \n",
    "    metadata[\"geometry2\"] = shapely.wkt.dumps(row.geometry, rounding_precision=7)   \n",
    "\n",
    "    PV.append(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b63a22-d857-49c2-af8a-0b4e02557095",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/energy/REC/MA/Arlington/'\n",
    "\n",
    "gpd . GeoDataFrame ( pd . DataFrame . from_dict ( PV ) ) . to_file ( data_dir + 'PV_complete.geojson' )\n",
    "\n",
    "print('#PVs',len(PV))\n",
    "pd . DataFrame . from_dict ( PV ) .reset_index(drop=True).to_csv(data_dir+'PV_complete.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4b4de-a660-4ca4-8964-70ad1fb32106",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd . DataFrame . from_dict ( PV ) \n",
    "shaft = data[['tokenId','street_number','street_name','value','cost','installer']].copy()\n",
    "\n",
    "shaft['diff']=shaft.cost-shaft.value\n",
    "\n",
    "(30*shaft.groupby('installer').agg({'diff':sum}).sort_values('diff')/1000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69275c76-f82d-46d0-bbbf-a6411a4b5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_permits = super_combo[super_combo._merge=='left_only'][ss.columns].sort_values('effective_date_permit').reset_index(drop=True)\n",
    "unmatched_permits['effective_date_permit'] = pd.to_datetime(unmatched_permits['effective_date_permit']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "print('complete',len(PV),'unmatched',len(unmatched_permits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55ddb6-5901-492a-bb51-e141ed02a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "permits_keys = {\n",
    "    \"financials\" : [\n",
    "        'contractor',\n",
    "        'permits',\n",
    "        'issued',\n",
    "        'descriptions',\n",
    "        'value',\n",
    "        'fee',\n",
    "    ],\n",
    "\n",
    "    \"dates\" : [\n",
    "        'effective_date_permit',\n",
    "    ],\n",
    "\n",
    "    \"location\" : [\n",
    "        'coord',\n",
    "        \"street_number\",\n",
    "        \"street_name\",\n",
    "        \"unit\" ,\n",
    "    ],\n",
    "\n",
    "    \"ohm\" : [\n",
    "        \"parcel_size\" ,\n",
    "        \"style\",\n",
    "        \"year_built\",\n",
    "        \"stories\",\n",
    "        \"units\",\n",
    "        \"rooms\",\n",
    "        \"gross_area\",\n",
    "        \"living_area\",\n",
    "    ],\n",
    "    \n",
    "    \"governance\" : [\n",
    "        \"parcel\",\n",
    "        \"land_use_code\",\n",
    "        \"zoning\",\n",
    "        \"location\",\n",
    "        \"map\",\n",
    "        \"plan\",\n",
    "        \"cama\",\n",
    "        \"deed_book\",\n",
    "        \"deed_page\",\n",
    "    ] ,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a058284-ce60-4dbc-ae69-e68e2208ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatchedPV          =  [ ] \n",
    "\n",
    "for jdx in range(len(unmatched_permits)):\n",
    "    \n",
    "    row = unmatched_permits.iloc[jdx]\n",
    "\n",
    "    metadata = {\n",
    "        \"tokenId\": row.tokenId,\n",
    "        \"image\" : row.image,\n",
    "        \"name\": row.street_number + ' ' + row.street_name,\n",
    "        \"description\": \"A photovoltaic system was installed at {address} on {effective_date} at a cost of {cost} by {installer}\". \\\n",
    "            format(address=row.street_number + ' ' + row.street_name,\n",
    "                   effective_date=row.effective_date_permit,\n",
    "                   cost=row.value,\n",
    "                   installer=row.contractor\n",
    "                  )\n",
    "    }\n",
    "        \n",
    "\n",
    "    for key in permits_keys.keys():\n",
    "        metadata[key] = convert_to_dict(row,permits_keys[key])\n",
    "                \n",
    "    metadata[\"geometry\"] = row.geometry  \n",
    "    metadata[\"geometry2\"] = shapely.wkt.dumps(row.geometry, rounding_precision=7)   \n",
    "\n",
    "    unmatchedPV.append(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e44a9-e5fa-47ca-8c28-e09b58b20a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unmatchedPV)\n",
    "pd . DataFrame . from_dict ( unmatchedPV ) .reset_index(drop=True).to_csv(data_dir+'PV_unmatched.tsv',sep='\\t',index=False)\n",
    "\n",
    "gpd . GeoDataFrame ( pd . DataFrame . from_dict ( PV+unmatchedPV ) ) . to_file ( data_dir + 'solar_systems.geojson' )\n",
    "\n",
    "both = pd . DataFrame . from_dict ( PV+unmatchedPV ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23685f18-3094-4086-9116-e4f2ac76991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe97b6-e48c-453a-9e33-0b0e105b0b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a015c98-aca3-4b22-b4a9-fe08b77814a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def defunct_debug():\n",
    "\n",
    "    ##rps only, check status of Approved only\n",
    "    mask = (rps_pts._merge=='left_only') & (rps_pts.status=='Approved')\n",
    "    cols = ['rps_rps','kW_rps','effective_date_rps','cost_rps']\n",
    "    rps_pts[mask][cols]#.to_csv(data_dir+'rps_only_for_match.tsv',sep='\\t',index=False)#[['pts','rps_rps']]\n",
    "\n",
    "    ##pts only, check status of Approved only\n",
    "    ##22 not matched\n",
    "    mask = (rps_pts._merge=='right_only') #& (rps_pts.status=='Approved')\n",
    "    cols = ['pts','kW_pts','effective_date_pts','cost_pts']\n",
    "    rps_pts[mask][cols]#.to_csv(data_dir+'pts_only_for_match.tsv',sep='\\t',index=False)#[['pts','rps_rps']]\n",
    "    \n",
    "    \n",
    "def defunctioin_name_matching() :\n",
    "\n",
    "    len(combo)\n",
    "    nn = pd.read_csv('/data/energy/REC/MA/name_fix.txt',sep='\\t')\n",
    "    combo.sort_values('rps_index').name\n",
    "\n",
    "    nn = pd.read_csv('/data/energy/REC/MA/name_fix.txt',sep='\\t')\n",
    "    combo['name_fix'] = nn\n",
    "    combo['name_fix'] = nn\n",
    "\n",
    "\n",
    "    mask = (pd.isnull(combo.name_fix))\n",
    "    mask.any()\n",
    "    mask = (~pd.isnull(combo.name_fix))#&(new_arl_combo.name_fix!='nan')\n",
    "    #names = new_arl_combo[mask].sort_values('effective_date_rps').name.str.replace('Arlington|Residence','').str.split('([A-Z])')\n",
    "    names = combo.name_fix.str.split('([A-Z])')\n",
    "    rps_names = (names.str[-2]+names.str[-1]).str.upper()\n",
    "    combo.loc[:,'last_name'] = rps_names\n",
    "\n",
    "    ## COMBINE with permits!!!\n",
    "    for idx in range(len(combo)):\n",
    "        rps_owner = new_arl_combo.loc[idx,'last_name'] \n",
    "        cost      = new_arl_combo.loc[idx,'cost_rps'] \n",
    "        date      = new_arl_combo.loc[idx,'effective_date_rps'] \n",
    "        if rps_owner == rps_owner:\n",
    "            mask = (solar_systems.owner.str.upper().str.contains(rps_owner)) &\\\n",
    "                ((date - pd.to_datetime(solar_systems.effective_date)<timedelta(days=30)) |\\\n",
    "                ((pd.to_datetime(solar_systems.effective_date) - date)<timedelta(days=30)) )\n",
    "            #&(np.abs(solar_systems['permit_value']-cost)<1000)\n",
    "            if len(solar_systems[mask])==1:\n",
    "                new_arl_combo.loc[idx,'tokenId']=int(solar_systems[mask].tokenId)\n",
    "            elif len(solar_systems[mask])>1:\n",
    "                print(idx,len(mask),'dups',rps_owner,cost,date)\n",
    "\n",
    "##defunct hand merger for rps, pts\n",
    "\n",
    "def rps_pts_manual_merge():  ##defunct?  one time?\n",
    "\n",
    "    cols = ['kW','effective_date','cost']\n",
    "    arl_pts_matcher = arl_pts[cols].copy().reset_index()#.to_csv('/data/energy/REC/MA/arl_pts.tsv',sep='\\t')\n",
    "    arl_rps_matcher = arl_rps[cols].copy().reset_index()#.to_csv('/data/energy/REC/MA/arl_rps.tsv',sep='\\t')\n",
    "\n",
    "    arl_rps_matcher.columns = ['rps','kW_rps','effective_date_rps','cost_rps']\n",
    "    arl_rps_matcher.effective_date_rps = pd.to_datetime(arl_rps_matcher.effective_date_rps)\n",
    "\n",
    "    arl_pts_matcher.columns = ['pts','kW_pts','effective_date_pts','cost_pts']\n",
    "    arl_pts_matcher.effective_date_pts = pd.to_datetime(arl_pts_matcher.effective_date_pts)\n",
    "\n",
    "\n",
    "    ## also use kW match <=0.005\n",
    "    foo=arl_rps_matcher.merge(arl_pts_matcher,right_on='cost_pts',left_on='cost_rps',indicator=True)\n",
    "    foo.to_csv('/data/energy/REC/MA/arl_rps_pts_join.tsv',sep='\\t')\n",
    "    #[arl_rps_matcher.duplicated()]\n",
    "\n",
    "    rps_pts_xref = pd.read_csv('/data/energy/REC/MA/rps_pts_xref.tsv',sep='\\t')\n",
    "    print('RPS dups:',rps_pts_xref.rps.duplicated().any(),'\\nPTS dups:',rps_pts_xref.pts.duplicated().any())\n",
    "\n",
    "    foo=arl_rps.reset_index(drop=True)\n",
    "    foo['rps_index'] = foo.index.astype(int)\n",
    "    foo\n",
    "\n",
    "    foo2 = arl_pts.reset_index(drop=True)\n",
    "    foo2['pts_index'] = foo2.index.astype(int)\n",
    "\n",
    "    foo = foo.merge(rps_pts_xref,how='outer',left_on='rps_index',right_on='rps')\n",
    "\n",
    "    foo = foo.merge(foo2,how='outer',left_on='pts',right_on='pts_index')\n",
    "\n",
    "    foo.to_csv('/data/energy/REC/MA/rps_pts_merged.tsv',sep='\\t',index=False)  #hand job exceptions\n",
    "    foo[(foo.rps_index.duplicated())&(~pd.isnull(foo.rps_index))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
